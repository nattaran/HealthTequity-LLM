{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "runtime_attributes": {
        "runtime_version": "2025.07"
      },
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nattaran/HealthTequity-LLM/blob/main/VoicePipeline_Drive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount Google Drive"
      ],
      "metadata": {
        "id": "VRRdbskvhjPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Clone or update repo inside Drive\n",
        "repo_url = \"https://github.com/nattaran/HealthTequity-LLM.git\"\n",
        "repo_path = \"/content/drive/MyDrive/HealthTequity-LLM\"\n",
        "\n",
        "import os\n",
        "if not os.path.exists(repo_path):\n",
        "    !git clone {repo_url} {repo_path}\n",
        "else:\n",
        "    %cd {repo_path}\n",
        "    !git fetch origin\n",
        "    !git pull\n",
        "\n",
        "%cd {repo_path}\n",
        "print(\"✅ Environment ready. Working from:\", os.getcwd())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ud6WBW1qUEqF",
        "outputId": "0f2ecb82-5fa6-4d02-baaf-065bae107cc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Cloning into '/content/drive/MyDrive/HealthTequity-LLM'...\n",
            "remote: Enumerating objects: 92, done.\u001b[K\n",
            "remote: Counting objects: 100% (92/92), done.\u001b[K\n",
            "remote: Compressing objects: 100% (87/87), done.\u001b[K\n",
            "remote: Total 92 (delta 35), reused 36 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (92/92), 1.95 MiB | 5.01 MiB/s, done.\n",
            "Resolving deltas: 100% (35/35), done.\n",
            "/content/drive/MyDrive/HealthTequity-LLM\n",
            "✅ Environment ready. Working from: /content/drive/MyDrive/HealthTequity-LLM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# 🚀 PROJECT BOOTSTRAP: Mount Drive + Git Clone + Folder Setup\n",
        "# ==========================================================\n",
        "\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "import os, shutil\n",
        "\n",
        "# --- 1️⃣ Mount Google Drive (persistent storage) ---\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- 2️⃣ Repo configuration ---\n",
        "repo_url  = \"https://github.com/yourusername/HealthTequity-LLM.git\"  # 🔁 replace with yours\n",
        "drive_root = Path(\"/content/drive/MyDrive/HealthTequity-LLM\")\n",
        "\n",
        "# --- 3️⃣ Clone or update repo inside Drive ---\n",
        "if not drive_root.exists():\n",
        "    print(\"🔹 Cloning repository into Google Drive...\")\n",
        "    !git clone {repo_url} {drive_root}\n",
        "else:\n",
        "    print(\"🔹 Repository already exists. Pulling latest updates...\")\n",
        "    %cd {drive_root}\n",
        "    !git fetch origin\n",
        "    !git pull\n",
        "\n",
        "%cd {drive_root}\n",
        "\n",
        "# --- 4️⃣ Verify core project folders ---\n",
        "DATA_DIR   = drive_root / \"data\"\n",
        "RESULTS_DIR = drive_root / \"results\"\n",
        "CSV_DIR    = DATA_DIR / \"synthetic_csv\"\n",
        "AUDIO_DIR  = DATA_DIR / \"Spanish_audio\"\n",
        "LLM_OUT    = RESULTS_DIR / \"llm_outputs\"\n",
        "EVAL_DIR   = RESULTS_DIR / \"evaluation_metrics\"\n",
        "TTS_DIR    = RESULTS_DIR / \"tts_audio\"\n",
        "\n",
        "# Create output dirs if missing\n",
        "for path in [RESULTS_DIR, LLM_OUT, EVAL_DIR, TTS_DIR]:\n",
        "    path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"\\n✅ Environment ready and folders verified:\")\n",
        "for p in [DATA_DIR, CSV_DIR, AUDIO_DIR, LLM_OUT, EVAL_DIR]:\n",
        "    print(\"  📂\", p)\n",
        "\n",
        "# --- 5️⃣ Optional: install dependencies automatically ---\n",
        "req_file = drive_root / \"requirements.txt\"\n",
        "if req_file.exists():\n",
        "    print(\"\\n🔹 Installing dependencies from requirements.txt ...\")\n",
        "    !pip install -r {req_file}\n",
        "else:\n",
        "    print(\"\\nℹ️ No requirements.txt found — skipping dependency install.\")\n",
        "\n",
        "print(\"\\n🎯 Ready to run pipeline from:\", drive_root)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db0XafXzVFjU",
        "outputId": "97e3caf6-91cb-4758-de31-0098f0ed0093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "🔹 Repository already exists. Pulling latest updates...\n",
            "/content/drive/MyDrive/HealthTequity-LLM\n",
            "Already up to date.\n",
            "/content/drive/MyDrive/HealthTequity-LLM\n",
            "\n",
            "✅ Environment ready and folders verified:\n",
            "  📂 /content/drive/MyDrive/HealthTequity-LLM/data\n",
            "  📂 /content/drive/MyDrive/HealthTequity-LLM/data/synthetic_csv\n",
            "  📂 /content/drive/MyDrive/HealthTequity-LLM/data/Spanish_audio\n",
            "  📂 /content/drive/MyDrive/HealthTequity-LLM/results/llm_outputs\n",
            "  📂 /content/drive/MyDrive/HealthTequity-LLM/results/evaluation_metrics\n",
            "\n",
            "🔹 Installing dependencies from requirements.txt ...\n",
            "Collecting git+https://github.com/openai/whisper.git (from -r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 22))\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-g3s2pavs\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-g3s2pavs\n",
            "  Resolved https://github.com/openai/whisper.git to commit c0d2f624c09dc18e709e37c2ad90c039a4eb72a2\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 6)) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 7)) (2.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.8.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 8)) (3.10.0)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 11)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchaudio>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 12)) (2.6.0+cu124)\n",
            "Requirement already satisfied: openai>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 15)) (1.95.1)\n",
            "Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 16)) (0.9.0)\n",
            "Collecting whisper (from -r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 20))\n",
            "  Downloading whisper-1.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ffmpeg-python>=0.2.0 (from -r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 25))\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 26)) (0.13.1)\n",
            "Requirement already satisfied: librosa>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 27)) (0.11.0)\n",
            "Requirement already satisfied: pydub>=0.25.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 28)) (0.25.1)\n",
            "Collecting jiwer>=3.0.3 (from -r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 31))\n",
            "  Downloading jiwer-4.0.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting python-Levenshtein>=0.25.0 (from -r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 32))\n",
            "  Downloading python_levenshtein-0.27.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting gtts>=2.3.2 (from -r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 35))\n",
            "  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting deep-translator>=1.11.4 (from -r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 36))\n",
            "  Downloading deep_translator-1.11.4-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting python-dotenv>=1.0.1 (from -r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 39))\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 40)) (4.67.1)\n",
            "Collecting vosk==0.3.45 (from -r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 43))\n",
            "  Downloading vosk-0.3.45-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from vosk==0.3.45->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 43)) (1.17.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from vosk==0.3.45->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 43)) (2.32.3)\n",
            "Collecting srt (from vosk==0.3.45->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 43))\n",
            "  Downloading srt-3.5.3.tar.gz (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.11/dist-packages (from vosk==0.3.45->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 43)) (15.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 7)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 7)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 7)) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.8.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 8)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.8.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 8)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.8.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 8)) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.8.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 8)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.8.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 8)) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.8.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 8)) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.8.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 8)) (3.2.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 11)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 11)) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 11)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 11)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 11)) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.1.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 11))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.1.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 11))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.1.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 11))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.1.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 11))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.1.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 11))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.1.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 11))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.1.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 11))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.1.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 11))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.1.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 11))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 11)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 11)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 11)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.1.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 11))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 11)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 11)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.12.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 15)) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.12.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 15)) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.12.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 15)) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.12.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 15)) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.12.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 15)) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.12.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 15)) (1.3.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.6.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 16)) (2024.11.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from whisper->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 20)) (1.17.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 22)) (10.7.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20250625->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 22)) (0.60.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python>=0.2.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 25)) (1.0.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 27)) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 27)) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 27)) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 27)) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 27)) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 27)) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 27)) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 27)) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 27)) (1.1.1)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer>=3.0.3->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 31)) (8.2.1)\n",
            "Collecting rapidfuzz>=3.9.7 (from jiwer>=3.0.3->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 31))\n",
            "  Downloading rapidfuzz-3.14.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
            "Collecting Levenshtein==0.27.1 (from python-Levenshtein>=0.25.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 32))\n",
            "  Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting click>=8.1.8 (from jiwer>=3.0.3->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 31))\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.11/dist-packages (from deep-translator>=1.11.4->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 36)) (4.13.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai>=1.12.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 15)) (3.10)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator>=1.11.4->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 36)) (2.7)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->vosk==0.3.45->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 43)) (2.22)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.12.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 15)) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.12.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 15)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.12.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 15)) (0.16.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper==20250625->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 22)) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa>=0.10.1->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 27)) (4.3.8)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai>=1.12.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 15)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai>=1.12.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 15)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai>=1.12.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 15)) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->vosk==0.3.45->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 43)) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->vosk==0.3.45->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 43)) (2.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa>=0.10.1->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 27)) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.0->-r /content/drive/MyDrive/HealthTequity-LLM/requirements.txt (line 11)) (3.0.2)\n",
            "Downloading vosk-0.3.45-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m107.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Downloading jiwer-4.0.0-py3-none-any.whl (23 kB)\n",
            "Downloading python_levenshtein-0.27.1-py3-none-any.whl (9.4 kB)\n",
            "Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
            "Downloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.14.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m116.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: whisper, openai-whisper, srt\n",
            "  Building wheel for whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for whisper: filename=whisper-1.1.10-py3-none-any.whl size=41120 sha256=00373ddc5ebc7eca2f86762b81edae6c4291112d792f70523353584ce13360e2\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/65/ee/4e6672aabfa486d3341a39a04f8f87c77e5156149299b5a7d0\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=38099fb18be6f8d7caa23911cc6ebd8ef6b97f5335020bfa2a86402853da8413\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-69sgay_o/wheels/1f/1d/98/9583695e6695a6ac0ad42d87511097dce5ba486647dbfecb0e\n",
            "  Building wheel for srt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for srt: filename=srt-3.5.3-py3-none-any.whl size=22427 sha256=87794c1beb5def68150c6232097197d193c72a442183fbcfadea8b7b5b25cbbc\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/43/f1/23ee9119497fcb57d9f7046fbf34c6d9027c46a1fa7824cf08\n",
            "Successfully built whisper openai-whisper srt\n",
            "Installing collected packages: whisper, srt, rapidfuzz, python-dotenv, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ffmpeg-python, click, vosk, nvidia-cusparse-cu12, nvidia-cudnn-cu12, Levenshtein, jiwer, gtts, deep-translator, python-Levenshtein, nvidia-cusolver-cu12, openai-whisper\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.2.1\n",
            "    Uninstalling click-8.2.1:\n",
            "      Successfully uninstalled click-8.2.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed Levenshtein-0.27.1 click-8.1.8 deep-translator-1.11.4 ffmpeg-python-0.2.0 gtts-2.5.4 jiwer-4.0.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-whisper-20250625 python-Levenshtein-0.27.1 python-dotenv-1.1.1 rapidfuzz-3.14.1 srt-3.5.3 vosk-0.3.45 whisper-1.1.10\n",
            "\n",
            "🎯 Ready to run pipeline from: /content/drive/MyDrive/HealthTequity-LLM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# 🧭 ENVIRONMENT & PATH VERIFICATION HELPER\n",
        "# ==========================================================\n",
        "import platform\n",
        "import torch\n",
        "\n",
        "def verify_environment():\n",
        "    \"\"\"Check core paths, Python env, and GPU status.\"\"\"\n",
        "    print(\"🔍 Environment Verification\\n\" + \"=\"*40)\n",
        "\n",
        "    # --- Project directories ---\n",
        "    paths = {\n",
        "        \"Project Root\": drive_root,\n",
        "        \"Data Dir\": DATA_DIR,\n",
        "        \"CSV Dir\": CSV_DIR,\n",
        "        \"Audio Dir\": AUDIO_DIR,\n",
        "        \"Results Dir\": RESULTS_DIR,\n",
        "        \"LLM Outputs\": LLM_OUT,\n",
        "        \"Eval Dir\": EVAL_DIR,\n",
        "        \"TTS Dir\": TTS_DIR,\n",
        "    }\n",
        "\n",
        "    print(\"\\n📁 Folder Paths:\")\n",
        "    for name, path in paths.items():\n",
        "        print(f\"  • {name:<15}: {'✅ Exists' if path.exists() else '❌ Missing'}  → {path}\")\n",
        "\n",
        "    # --- Python & system info ---\n",
        "    print(\"\\n🧠 System Info:\")\n",
        "    print(f\"  • Python version : {platform.python_version()}\")\n",
        "    print(f\"  • Platform       : {platform.system()} {platform.release()}\")\n",
        "\n",
        "    # --- GPU / CUDA info ---\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"\\n⚙️  GPU Available  : ✅ {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"  • CUDA version   : {torch.version.cuda}\")\n",
        "    else:\n",
        "        print(\"\\n⚙️  GPU Available  : ❌ (CPU mode)\")\n",
        "\n",
        "    print(\"\\n✅ Environment verification complete.\\n\")\n",
        "\n",
        "# --- Run check ---\n",
        "verify_environment()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87ncs6XjWDmY",
        "outputId": "2e943502-8a99-472d-ca73-9501071c0d6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Environment Verification\n",
            "========================================\n",
            "\n",
            "📁 Folder Paths:\n",
            "  • Project Root   : ✅ Exists  → /content/drive/MyDrive/HealthTequity-LLM\n",
            "  • Data Dir       : ✅ Exists  → /content/drive/MyDrive/HealthTequity-LLM/data\n",
            "  • CSV Dir        : ✅ Exists  → /content/drive/MyDrive/HealthTequity-LLM/data/synthetic_csv\n",
            "  • Audio Dir      : ✅ Exists  → /content/drive/MyDrive/HealthTequity-LLM/data/Spanish_audio\n",
            "  • Results Dir    : ✅ Exists  → /content/drive/MyDrive/HealthTequity-LLM/results\n",
            "  • LLM Outputs    : ✅ Exists  → /content/drive/MyDrive/HealthTequity-LLM/results/llm_outputs\n",
            "  • Eval Dir       : ✅ Exists  → /content/drive/MyDrive/HealthTequity-LLM/results/evaluation_metrics\n",
            "  • TTS Dir        : ✅ Exists  → /content/drive/MyDrive/HealthTequity-LLM/results/tts_audio\n",
            "\n",
            "🧠 System Info:\n",
            "  • Python version : 3.11.13\n",
            "  • Platform       : Linux 6.6.105+\n",
            "\n",
            "⚙️  GPU Available  : ❌ (CPU mode)\n",
            "\n",
            "✅ Environment verification complete.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load OpenAI API Key (From secretes)"
      ],
      "metadata": {
        "id": "os1Ys4uqh21X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# 🔑 OPENAI CLIENT (COLAB-SECURE)\n",
        "# ==========================================================\n",
        "import os\n",
        "from getpass import getpass\n",
        "from openai import OpenAI\n",
        "\n",
        "# Ask for key only if it isn't set yet\n",
        "# if \"OPENAI_API_KEY\" not in os.environ or not os.environ[\"OPENAI_API_KEY\"]:\n",
        "#     os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OPENAI_API_KEY: \")\n",
        "\n",
        "\n",
        "key = os.getenv(\"OPENAI_API_KEY\")\n",
        "print(\"✅ Key loaded successfully!\" if key else \"❌ Key not found.\")\n",
        "\n",
        "\n",
        "#client = OpenAI()\n",
        "# print(\"✅ OpenAI client initialized successfully.\")\n"
      ],
      "metadata": {
        "id": "1q-eJA5XgloP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5100ea53-fd3a-4c30-8379-0ad12c93cb39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Key not found.\n",
            "✅ OpenAI client initialized successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "print(\"✅ Whisper module path:\", whisper.__file__)\n",
        "print(\"✅ Available attributes:\", [m for m in dir(whisper) if \"load\" in m])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhpKk1FN6d6v",
        "outputId": "553919b2-a4b4-4fff-e35d-636ebf088ae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Whisper module path: /usr/local/lib/python3.11/dist-packages/whisper/__init__.py\n",
            "✅ Available attributes: ['__loader__', '_download', 'load_audio', 'load_model']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install git+https://github.com/openai/whisper.git"
      ],
      "metadata": {
        "id": "tMGBueLNwuLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# 🎙️ STEP 4 — TRANSCRIBE (SPANISH) ➜ TRANSLATE (ENGLISH)\n",
        "# ==========================================================\n",
        "import os\n",
        "import pandas as pd\n",
        "import whisper\n",
        "from pathlib import Path\n",
        "\n",
        "# --- 1️⃣ Transcription Function ---\n",
        "def transcribe_spanish_audio(model, audio_path: Path):\n",
        "    print(f\"🎧 Transcribing: {audio_path.name}\")\n",
        "    result = model.transcribe(str(audio_path), language=\"es\", task=\"transcribe\", verbose=False)\n",
        "    return result[\"text\"].strip(), result.get(\"language\", \"unknown\")\n",
        "\n",
        "# --- 2️⃣ Translation Function ---\n",
        "def translate_spanish_to_english(spanish_text: str) -> str:\n",
        "    \"\"\"Translate Spanish transcription to English.\"\"\"\n",
        "    prompt = f\"Translate the following Spanish medical transcription into clear English:\\n\\n{spanish_text}\"\n",
        "    result = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        temperature=0,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return result.choices[0].message.content.strip()\n",
        "\n",
        "# --- 3️⃣ Full Pipeline ---\n",
        "def process_and_translate_audio(audio_folder: Path, output_csv: Path):\n",
        "    \"\"\"\n",
        "    Runs Whisper ASR on all .wav files in audio_folder,\n",
        "    translates Spanish → English, and saves to CSV.\n",
        "    \"\"\"\n",
        "    model = whisper.load_model(\"base\")\n",
        "    all_results = []\n",
        "\n",
        "    audio_files = sorted([f for f in os.listdir(audio_folder) if f.endswith(\".wav\")])\n",
        "\n",
        "    print(\"\\n🎯 STARTING SPANISH TRANSCRIPTION + TRANSLATION\\n\" + \"=\"*60)\n",
        "    for i, audio_file in enumerate(audio_files, 1):\n",
        "        audio_path = audio_folder / audio_file\n",
        "        if not audio_path.exists():\n",
        "            print(f\"⚠️ {audio_file} not found, skipping...\")\n",
        "            continue\n",
        "\n",
        "        spanish_text, detected_lang = transcribe_spanish_audio(model, audio_path)\n",
        "        english_text = translate_spanish_to_english(spanish_text)\n",
        "\n",
        "        all_results.append({\n",
        "            \"audio_file\": audio_file,\n",
        "            \"spanish_transcription\": spanish_text,\n",
        "            \"english_translation\": english_text,\n",
        "            \"language_detected\": detected_lang\n",
        "        })\n",
        "\n",
        "        print(f\"\\n[{i}] {audio_file}\")\n",
        "        print(f\"🇪🇸 {spanish_text}\")\n",
        "        print(f\"🇬🇧 {english_text}\")\n",
        "\n",
        "    df = pd.DataFrame(all_results)\n",
        "    df.to_csv(output_csv, index=False, encoding=\"utf-8-sig\")\n",
        "    print(f\"\\n✅ Transcriptions + translations saved to {output_csv}\")\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "X1WdMwD_5haz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# 🚀 RUN TRANSCRIPTION + TRANSLATION PIPELINE\n",
        "# ==========================================================\n",
        "output_csv = LLM_OUT / \"asr_translation_results.csv\"\n",
        "df_results = process_and_translate_audio(AUDIO_DIR, output_csv)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCPGKC1w629N",
        "outputId": "6863db05-6a4f-4cf9-b868-9be6e17466d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|████████████████████████████████████████| 139M/139M [00:00<00:00, 177MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🎯 STARTING SPANISH TRANSCRIPTION + TRANSLATION\n",
            "============================================================\n",
            "🎧 Transcribing: q1_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "100%|██████████| 458/458 [00:03<00:00, 118.82frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[1] q1_es.wav\n",
            "🇪🇸 ¿Cuáles son mis presiones arteriales histólica y diastólica hoy?\n",
            "🇬🇧 What are my systolic and diastolic blood pressures today?\n",
            "🎧 Transcribing: q2_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "100%|██████████| 470/470 [00:03<00:00, 126.63frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[2] q2_es.wav\n",
            "🇪🇸 ¿Cuáles fueron mis valores de presión arterial durante la última semana?\n",
            "🇬🇧 What were my blood pressure readings over the last week?\n",
            "🎧 Transcribing: q3_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "100%|██████████| 369/369 [00:02<00:00, 136.17frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[3] q3_es.wav\n",
            "🇪🇸 ¿Cuál es la tendencia de mis valores de presión arterial?\n",
            "🇬🇧 What is the trend of my blood pressure values?\n",
            "🎧 Transcribing: q4_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "100%|██████████| 398/398 [00:02<00:00, 143.60frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[4] q4_es.wav\n",
            "🇪🇸 ¿Cuáles son los rango normales para una persona como yo?\n",
            "🇬🇧 What are the normal ranges for a person like me?\n",
            "🎧 Transcribing: q5_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "100%|██████████| 328/328 [00:04<00:00, 76.62frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[5] q5_es.wav\n",
            "🇪🇸 ¿Cuál era mi presión arterial el 10 de octubre?\n",
            "🇬🇧 What was my blood pressure on October 10th?\n",
            "🎧 Transcribing: q6_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "100%|██████████| 1574/1574 [00:05<00:00, 298.58frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[6] q6_es.wav\n",
            "🇪🇸 ¿En qué día mi presión arterial excedió los niveles normales? Compare mi presión arterial promedio en la primera semana y la última semana de este mes. ¿Cuál fue mi presión arterial diastólica más baja este mes?\n",
            "🇬🇧 On what day did my blood pressure exceed normal levels? Compare my average blood pressure in the first week and the last week of this month. What was my lowest diastolic blood pressure this month?\n",
            "\n",
            "✅ Transcriptions + translations saved to /content/drive/MyDrive/HealthTequity-LLM/results/llm_outputs/asr_translation_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# 🧮 ASR PERFORMANCE EVALUATION (WER, CER, SER)\n",
        "# ==========================================================\n",
        "import pandas as pd\n",
        "import Levenshtein\n",
        "from jiwer import process_words\n",
        "from pathlib import Path\n",
        "\n",
        "def compute_cer(reference: str, hypothesis: str) -> float:\n",
        "    reference, hypothesis = reference.strip(), hypothesis.strip()\n",
        "    if not reference:\n",
        "        return 1.0 if hypothesis else 0.0\n",
        "    return Levenshtein.distance(reference, hypothesis) / len(reference)\n",
        "\n",
        "def compute_sentence_error(reference: str, hypothesis: str) -> int:\n",
        "    return 0 if reference.strip() == hypothesis.strip() else 1\n",
        "\n",
        "def evaluate_asr_performance(ground_truth_csv: Path, transcribed_csv: Path, output_csv: Path):\n",
        "    gt_df = pd.read_csv(ground_truth_csv)\n",
        "    tr_df = pd.read_csv(transcribed_csv)\n",
        "\n",
        "    gt_df.columns = [c.lower().strip() for c in gt_df.columns]\n",
        "    tr_df.columns = [c.lower().strip() for c in tr_df.columns]\n",
        "\n",
        "    df = pd.merge(gt_df, tr_df, on=\"audio_file\", how=\"inner\")\n",
        "\n",
        "    results = []\n",
        "    print(f\"\\n🎯 Evaluating {len(df)} audio files for ASR performance...\\n\")\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        ref, hyp = str(row[\"ground_truth\"]), str(row[\"spanish_transcription\"])\n",
        "        m = process_words(ref, hyp)\n",
        "        wer_score = round(m.wer, 4)\n",
        "        cer = round(compute_cer(ref, hyp), 4)\n",
        "        ser = compute_sentence_error(ref, hyp)\n",
        "\n",
        "        results.append({\n",
        "            \"audio_file\": row[\"audio_file\"],\n",
        "            \"WER\": wer_score,\n",
        "            \"Substitutions\": m.substitutions,\n",
        "            \"Deletions\": m.deletions,\n",
        "            \"Insertions\": m.insertions,\n",
        "            \"CER\": cer,\n",
        "            \"SER\": ser\n",
        "        })\n",
        "        print(f\"🎧 {row['audio_file']} → WER: {wer_score}, CER: {cer}, SER: {ser}\")\n",
        "\n",
        "    out_df = pd.DataFrame(results)\n",
        "    out_df.to_csv(output_csv, index=False)\n",
        "    print(f\"\\n✅ ASR metrics saved to: {output_csv}\")\n",
        "    return out_df\n"
      ],
      "metadata": {
        "id": "jjGFLOSQgBNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth_csv = CSV_DIR / \"ground_truth.csv\"\n",
        "transcribed_csv  = LLM_OUT / \"asr_translation_results.csv\"\n",
        "output_metrics   = EVAL_DIR / \"asr_metrics.csv\"\n",
        "\n",
        "df_metrics = evaluate_asr_performance(ground_truth_csv, transcribed_csv, output_metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bSE5Ztq2-6o",
        "outputId": "ebd46d57-3ade-4598-9e9d-dfcb1d79c3a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🎯 Evaluating 6 audio files for ASR performance...\n",
            "\n",
            "🎧 q1_es.wav → WER: 0.1111, CER: 0.0156, SER: 1\n",
            "🎧 q2_es.wav → WER: 0.0, CER: 0.0, SER: 0\n",
            "🎧 q3_es.wav → WER: 0.0, CER: 0.0, SER: 0\n",
            "🎧 q4_es.wav → WER: 0.1, CER: 0.0175, SER: 1\n",
            "🎧 q5_es.wav → WER: 0.0, CER: 0.0, SER: 0\n",
            "🎧 q6_es.wav → WER: 0.0, CER: 0.0, SER: 0\n",
            "\n",
            "✅ ASR metrics saved to: /content/drive/MyDrive/HealthTequity-LLM/results/evaluation_metrics/asr_metrics.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM Section\n",
        "\n",
        "# ================================================================\n",
        "# 🤖 STEP — GPT BLOOD PRESSURE ANALYSIS + TRANSLATION + TTS\n",
        "# ================================================================\n",
        "import json, re, os\n",
        "from openai import OpenAI\n",
        "from pathlib import Path\n",
        "\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "# --- 🧠 Updated System Instruction ---\n",
        "SYSTEM = \"\"\"\n",
        "You are a careful and detail-oriented data analyst.\n",
        "\n",
        "You are given a synthetic blood pressure dataset in CSV format. It contains readings for one individual over the last 30 consecutive days, with the following columns:\n",
        "\n",
        "- date\n",
        "- age\n",
        "- sex\n",
        "- systolic_mmHg\n",
        "- diastolic_mmHg\n",
        "\n",
        "Use only the data in the CSV to answer all questions, except when normal blood pressure ranges are requested — in those cases, you may use external references but must cite your source.\n",
        "\n",
        "---\n",
        "\n",
        "🧠 Interpretation Guidelines:\n",
        "\n",
        "- \"Today\" refers to the most recent date in the dataset.\n",
        "- \"Yesterday\" means the most recent date before \"today\", based on available data.\n",
        "- Phrases like \"last week\" or \"last month\" refer to calendar-based timeframes (e.g., the 7 or 30 days before \"today\"), not just row counts.\n",
        "- If a question refers to a specific date or date range that is not present in the dataset, clearly state that the data is unavailable.\n",
        "- Use conversational date formats like “October 12” or “October 12 to 15” — avoid numeric formats like “10/12/2025”.\n",
        "\n",
        "---\n",
        "\n",
        "💬 Answer Style:\n",
        "\n",
        "- Write in natural, conversational English.\n",
        "- Address the user directly using “you” (e.g., “Your blood pressure was…”).\n",
        "\n",
        "---\n",
        "\n",
        "✅ Response Format:\n",
        "\n",
        "Return all answers in the following JSON format:\n",
        "\n",
        "{ \"answer\": \"<English answer>\", \"computed_fields\": { \"numeric values used\" } }\n",
        "\n",
        "---\n",
        "\n",
        "📌 Example Questions and Answers:\n",
        "\n",
        "These illustrate tone and structure only. Actual answers must be based on the CSV data.\n",
        "\n",
        "Q: What are my systolic_mmHg and diastolic_mmHg blood pressures today?\n",
        "A: Your systolic blood pressure was [xx] mm Hg and your diastolic pressure was [yy] mm Hg today.\n",
        "\n",
        "Q: What were the values over the last week?\n",
        "A: Over the last 7 days, your systolic pressure averaged [xx] mm Hg and your diastolic pressure averaged [yy] mm Hg.\n",
        "\n",
        "Q: What is the trend of my blood pressure?\n",
        "A: Your blood pressure has shown a gradual increase in systolic values over the last 30 days, while your diastolic readings have remained stable.\n",
        "\n",
        "Q: What are the normal ranges for a person like me?\n",
        "A: Based on your age ([age from dataset] years) and sex ([male/female]), typical blood pressure values are approximately [xx/yy] mm Hg, according to [name and link to the external source].\n",
        "\"\"\"\n",
        "\n",
        "# --- 1️⃣ Ask GPT to analyze CSV ---\n",
        "def ask_gpt(question_en: str, csv_block: str):\n",
        "    \"\"\"Ask GPT to analyze CSV data and return JSON-formatted answers.\"\"\"\n",
        "    user = f\"CSV data:\\n{csv_block}\\n\\nQUESTION:\\n{question_en}\"\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        temperature=0.1,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": SYSTEM},\n",
        "            {\"role\": \"user\", \"content\": user}\n",
        "        ]\n",
        "    ).choices[0].message.content\n",
        "\n",
        "    # Extract JSON safely\n",
        "    clean = re.sub(r\"^```json|```$\", \"\", resp.strip(), flags=re.M | re.I)\n",
        "    start, end = clean.find(\"{\"), clean.rfind(\"}\")\n",
        "    return json.loads(clean[start:end+1])\n",
        "\n",
        "# --- 2️⃣ English → Spanish translation ---\n",
        "def translate_to_spanish(english_text: str) -> str:\n",
        "    \"\"\"Translate GPT's English output into clear, neutral Spanish.\"\"\"\n",
        "    prompt = f\"Translate this English medical answer into clear, neutral Spanish:\\n{english_text}\"\n",
        "    return client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        temperature=0,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    ).choices[0].message.content.strip()\n",
        "\n",
        "# --- 3️⃣ Spanish Text-to-Speech (TTS) ---\n",
        "def text_to_speech_spanish(text: str, out_path: Path, voice=\"alloy\") -> Path:\n",
        "    \"\"\"Generate a Spanish TTS audio file for the final translated response.\"\"\"\n",
        "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with client.audio.speech.with_streaming_response.create(\n",
        "        model=\"gpt-4o-mini-tts\", voice=voice, input=text\n",
        "    ) as response:\n",
        "        response.stream_to_file(str(out_path))\n",
        "    print(f\"🔊 Saved Spanish audio: {out_path}\")\n",
        "    return out_path\n"
      ],
      "metadata": {
        "id": "A5Vb3EJW8HV3"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Whiper ASR to convert the spanish Audio to text to evaluate the error rate"
      ],
      "metadata": {
        "id": "3loaYN6wxc4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper, re, unicodedata, Levenshtein, pandas as pd\n",
        "from jiwer import process_words\n",
        "\n",
        "def normalize_text(text):\n",
        "    \"\"\"Lowercase, strip accents, remove punctuation for fair WER/CER.\"\"\"\n",
        "    text = text.lower()\n",
        "    text = ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', text)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "def evaluate_output_asr_whisper(\n",
        "    tts_csv,\n",
        "    output_csv=EVAL_DIR / \"output_asr_metrics_whisper.csv\",\n",
        "    model_size=\"base\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Evaluate the Spanish TTS audios using Whisper.\n",
        "    Computes WER, CER, and SER against ground truth Spanish answers.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(tts_csv):\n",
        "        raise FileNotFoundError(f\"❌ Missing final results CSV: {tts_csv}\")\n",
        "\n",
        "    print(f\"🎯 Loading Whisper ({model_size}) model ...\")\n",
        "    model = whisper.load_model(model_size)\n",
        "\n",
        "    df = pd.read_csv(tts_csv)\n",
        "    results = []\n",
        "\n",
        "    print(\"\\n🎧 Evaluating Spanish TTS output audios\\n\" + \"=\"*60)\n",
        "    for i, row in df.iterrows():\n",
        "        gt = str(row[\"spanish_answer\"]).strip()\n",
        "        audio_file = row[\"audio_answer_file\"]\n",
        "        if not os.path.exists(audio_file):\n",
        "            print(f\"⚠️ Missing audio file: {audio_file}\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # Transcribe with Whisper\n",
        "            result = model.transcribe(audio_file, language=\"es\", task=\"transcribe\", verbose=False)\n",
        "            hyp = result[\"text\"].strip()\n",
        "\n",
        "            # Normalize both texts\n",
        "            gt_norm = normalize_text(gt)\n",
        "            hyp_norm = normalize_text(hyp)\n",
        "\n",
        "            # Compute metrics\n",
        "            measures = process_words(gt_norm, hyp_norm)\n",
        "            wer_score = round(measures.wer, 4)\n",
        "            subs, dels, ins = measures.substitutions, measures.deletions, measures.insertions\n",
        "            cer = round(Levenshtein.distance(gt_norm, hyp_norm) / max(len(gt_norm), 1), 4)\n",
        "            ser = 0 if gt_norm == hyp_norm else 1\n",
        "\n",
        "            results.append({\n",
        "                \"audio_file\": os.path.basename(audio_file),\n",
        "                \"ground_truth\": gt,\n",
        "                \"whisper_transcription\": hyp,\n",
        "                \"WER\": wer_score,\n",
        "                \"Substitutions\": subs,\n",
        "                \"Deletions\": dels,\n",
        "                \"Insertions\": ins,\n",
        "                \"CER\": cer,\n",
        "                \"SER\": ser\n",
        "            })\n",
        "\n",
        "            print(f\"✅ {os.path.basename(audio_file)} → WER={wer_score}, CER={cer}, SER={ser}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error processing {audio_file}: {e}\")\n",
        "\n",
        "    out_df = pd.DataFrame(results)\n",
        "    out_df.to_csv(output_csv, index=False)\n",
        "    print(f\"\\n✅ Whisper ASR evaluation saved to: {output_csv}\")\n",
        "    return out_df"
      ],
      "metadata": {
        "id": "DgArTASYxbfS"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# 🚀 STEP — FULL PIPELINE: ASR → EVALUATION → LLM → TRANSLATION → TTS\n",
        "# ================================================================\n",
        "import json, pandas as pd, os\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def run_full_pipeline(csv_path: Path, audio_folder: Path):\n",
        "    \"\"\"\n",
        "    Runs the complete HealthTequity pipeline:\n",
        "    1. Transcribes and translates Spanish audio → English.\n",
        "    2. Evaluates ASR using ground truth (WER, CER, SER).\n",
        "    3. Uses LLM to analyze blood pressure dataset and answer each English question.\n",
        "    4. Translates answers to Spanish and generates Spanish TTS.\n",
        "    5. Saves all results to /results folders.\n",
        "    \"\"\"\n",
        "    # --- Step 1️⃣: Transcribe + Translate ---\n",
        "    trans_csv = LLM_OUT / \"audio_translations.csv\"\n",
        "    audio_files = sorted([f for f in os.listdir(audio_folder) if f.endswith(\".wav\")])\n",
        "    trans_df = process_and_translate_audio(audio_folder, trans_csv)\n",
        "\n",
        "    # --- Step 2️⃣: Evaluate ASR (WER, CER, SER) ---\n",
        "    gt_csv = CSV_DIR / \"ground_truth.csv\"\n",
        "    asr_csv = EVAL_DIR / \"asr_metrics.csv\"\n",
        "    asr_df = evaluate_asr_performance(gt_csv, trans_csv, asr_csv)\n",
        "\n",
        "    # --- Step 3️⃣: Load synthetic blood pressure CSV ---\n",
        "    df_bp = pd.read_csv(csv_path)\n",
        "    csv_block = df_bp.to_csv(index=False)\n",
        "\n",
        "    # --- Step 4️⃣: For each question, ask GPT and generate responses ---\n",
        "    results = []\n",
        "    print(\"\\n🎯 STARTING GPT QUESTION-ANSWER PIPELINE\\n\" + \"=\" * 60)\n",
        "\n",
        "    for i, row in trans_df.iterrows():\n",
        "        q_num = i + 1\n",
        "        q_en = row[\"english_translation\"]\n",
        "        print(f\"\\n🔹 Q{q_num}: {q_en}\")\n",
        "\n",
        "        try:\n",
        "            # LLM analysis\n",
        "            ans = ask_gpt(q_en, csv_block)\n",
        "            ans_en = ans.get(\"answer\", \"\").strip()\n",
        "\n",
        "            # Translate & synthesize\n",
        "            ans_es = translate_to_spanish(ans_en)\n",
        "            audio_answer_file = TTS_DIR / f\"answer_{q_num}_es.wav\"\n",
        "            text_to_speech_spanish(ans_es, audio_answer_file)\n",
        "\n",
        "            # Append all outputs\n",
        "            results.append({\n",
        "                \"question_number\": q_num,\n",
        "                \"audio_file_in\": row[\"audio_file\"],\n",
        "                \"spanish_question\": row[\"spanish_transcription\"],\n",
        "                \"english_question\": q_en,\n",
        "                \"english_answer\": ans_en,\n",
        "                \"spanish_answer\": ans_es,\n",
        "                \"audio_answer_file\": str(audio_answer_file),\n",
        "                \"computed_fields\": json.dumps(ans.get(\"computed_fields\", {}))\n",
        "            })\n",
        "\n",
        "            print(f\"✅ Completed Q{q_num}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error Q{q_num}: {e}\")\n",
        "\n",
        "    # --- Step 5️⃣: Save Final Results ---\n",
        "    final_csv = LLM_OUT / \"final_pipeline_results.csv\"\n",
        "    pd.DataFrame(results).to_csv(final_csv, index=False)\n",
        "    print(f\"\\n✅ Full pipeline completed successfully!\")\n",
        "    print(f\"📁 Final results saved to: {final_csv}\")\n",
        "    # --- Step 6️⃣: Evaluate TTS ASR using Whisper ---\n",
        "    print(\"\\n🎧 Starting Whisper evaluation of TTS outputs...\")\n",
        "    output_asr_csv = EVAL_DIR / \"output_asr_metrics_whisper.csv\"\n",
        "    evaluate_output_asr_whisper(final_csv, output_csv=output_asr_csv, model_size=\"base\")\n",
        "\n",
        "    print(\"\\n🏁 Pipeline completed including final Whisper evaluation.\")\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "Ac8UD1dI_ctt"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bp_csv = CSV_DIR / \"synthetic_bp_one_person.csv\"\n",
        "run_full_pipeline(bp_csv, AUDIO_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6YZCaLwAY3T",
        "outputId": "42be8c58-af06-4fed-f081-46777cb7aa8d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🎯 STARTING SPANISH TRANSCRIPTION + TRANSLATION\n",
            "============================================================\n",
            "🎧 Transcribing: q1_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "100%|██████████| 458/458 [00:03<00:00, 151.04frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[1] q1_es.wav\n",
            "🇪🇸 ¿Cuáles son mis presiones arteriales histólica y diastólica hoy?\n",
            "🇬🇧 What are my systolic and diastolic blood pressures today?\n",
            "🎧 Transcribing: q2_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "100%|██████████| 470/470 [00:02<00:00, 167.35frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[2] q2_es.wav\n",
            "🇪🇸 ¿Cuáles fueron mis valores de presión arterial durante la última semana?\n",
            "🇬🇧 What were my blood pressure readings over the last week?\n",
            "🎧 Transcribing: q3_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "100%|██████████| 369/369 [00:02<00:00, 124.06frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[3] q3_es.wav\n",
            "🇪🇸 ¿Cuál es la tendencia de mis valores de presión arterial?\n",
            "🇬🇧 What is the trend of my blood pressure values?\n",
            "🎧 Transcribing: q4_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "100%|██████████| 398/398 [00:03<00:00, 116.77frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[4] q4_es.wav\n",
            "🇪🇸 ¿Cuáles son los rango normales para una persona como yo?\n",
            "🇬🇧 What are the normal ranges for a person like me?\n",
            "🎧 Transcribing: q5_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "100%|██████████| 328/328 [00:02<00:00, 116.88frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[5] q5_es.wav\n",
            "🇪🇸 ¿Cuál era mi presión arterial el 10 de octubre?\n",
            "🇬🇧 What was my blood pressure on October 10th?\n",
            "🎧 Transcribing: q6_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "100%|██████████| 1574/1574 [00:05<00:00, 309.70frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[6] q6_es.wav\n",
            "🇪🇸 ¿En qué día mi presión arterial excedió los niveles normales? Compare mi presión arterial promedio en la primera semana y la última semana de este mes. ¿Cuál fue mi presión arterial diastólica más baja este mes?\n",
            "🇬🇧 On which day did my blood pressure exceed normal levels? Compare my average blood pressure in the first week and the last week of this month. What was my lowest diastolic blood pressure this month?\n",
            "\n",
            "✅ Transcriptions + translations saved to /content/drive/MyDrive/HealthTequity-LLM/results/llm_outputs/audio_translations.csv\n",
            "\n",
            "🎯 Evaluating 6 audio files for ASR performance...\n",
            "\n",
            "🎧 q1_es.wav → WER: 0.1111, CER: 0.0156, SER: 1\n",
            "🎧 q2_es.wav → WER: 0.0, CER: 0.0, SER: 0\n",
            "🎧 q3_es.wav → WER: 0.0, CER: 0.0, SER: 0\n",
            "🎧 q4_es.wav → WER: 0.1, CER: 0.0175, SER: 1\n",
            "🎧 q5_es.wav → WER: 0.0, CER: 0.0, SER: 0\n",
            "🎧 q6_es.wav → WER: 0.0, CER: 0.0, SER: 0\n",
            "\n",
            "✅ ASR metrics saved to: /content/drive/MyDrive/HealthTequity-LLM/results/evaluation_metrics/asr_metrics.csv\n",
            "\n",
            "🎯 STARTING GPT QUESTION-ANSWER PIPELINE\n",
            "============================================================\n",
            "\n",
            "🔹 Q1: What are my systolic and diastolic blood pressures today?\n",
            "🔊 Saved Spanish audio: /content/drive/MyDrive/HealthTequity-LLM/results/tts_audio/answer_1_es.wav\n",
            "✅ Completed Q1\n",
            "\n",
            "🔹 Q2: What were my blood pressure readings over the last week?\n",
            "🔊 Saved Spanish audio: /content/drive/MyDrive/HealthTequity-LLM/results/tts_audio/answer_2_es.wav\n",
            "✅ Completed Q2\n",
            "\n",
            "🔹 Q3: What is the trend of my blood pressure values?\n",
            "🔊 Saved Spanish audio: /content/drive/MyDrive/HealthTequity-LLM/results/tts_audio/answer_3_es.wav\n",
            "✅ Completed Q3\n",
            "\n",
            "🔹 Q4: What are the normal ranges for a person like me?\n",
            "🔊 Saved Spanish audio: /content/drive/MyDrive/HealthTequity-LLM/results/tts_audio/answer_4_es.wav\n",
            "✅ Completed Q4\n",
            "\n",
            "🔹 Q5: What was my blood pressure on October 10th?\n",
            "🔊 Saved Spanish audio: /content/drive/MyDrive/HealthTequity-LLM/results/tts_audio/answer_5_es.wav\n",
            "✅ Completed Q5\n",
            "\n",
            "🔹 Q6: On which day did my blood pressure exceed normal levels? Compare my average blood pressure in the first week and the last week of this month. What was my lowest diastolic blood pressure this month?\n",
            "🔊 Saved Spanish audio: /content/drive/MyDrive/HealthTequity-LLM/results/tts_audio/answer_6_es.wav\n",
            "✅ Completed Q6\n",
            "\n",
            "✅ Full pipeline completed successfully!\n",
            "📁 Final results saved to: /content/drive/MyDrive/HealthTequity-LLM/results/llm_outputs/final_pipeline_results.csv\n",
            "\n",
            "🎧 Starting Whisper evaluation of TTS outputs...\n",
            "🎯 Loading Whisper (base) model ...\n",
            "\n",
            "🎧 Evaluating Spanish TTS output audios\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "100%|██████████| 945/945 [00:03<00:00, 247.98frames/s]\n",
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ answer_1_es.wav → WER=0.4737, CER=0.2778, SER=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6276/6276 [01:06<00:00, 94.90frames/s]\n",
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ answer_2_es.wav → WER=0.2207, CER=0.2557, SER=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3681/3681 [00:12<00:00, 288.76frames/s]\n",
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ answer_3_es.wav → WER=0.0633, CER=0.0115, SER=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4324/4324 [00:11<00:00, 363.89frames/s]\n",
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ answer_4_es.wav → WER=0.1842, CER=0.1176, SER=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1024/1024 [00:04<00:00, 250.09frames/s]\n",
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ answer_5_es.wav → WER=0.2273, CER=0.2212, SER=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5952/5952 [00:18<00:00, 323.01frames/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ answer_6_es.wav → WER=0.0968, CER=0.0784, SER=1\n",
            "\n",
            "✅ Whisper ASR evaluation saved to: /content/drive/MyDrive/HealthTequity-LLM/results/evaluation_metrics/output_asr_metrics_whisper.csv\n",
            "\n",
            "🏁 Pipeline completed including final Whisper evaluation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'question_number': 1,\n",
              "  'audio_file_in': 'q1_es.wav',\n",
              "  'spanish_question': '¿Cuáles son mis presiones arteriales histólica y diastólica hoy?',\n",
              "  'english_question': 'What are my systolic and diastolic blood pressures today?',\n",
              "  'english_answer': 'Your systolic blood pressure was 110 mm Hg and your diastolic pressure was 76 mm Hg today.',\n",
              "  'spanish_answer': 'Su presión arterial sistólica fue de 110 mm Hg y su presión diastólica fue de 76 mm Hg hoy.',\n",
              "  'audio_answer_file': '/content/drive/MyDrive/HealthTequity-LLM/results/tts_audio/answer_1_es.wav',\n",
              "  'computed_fields': '{\"systolic_mmHg_today\": 110, \"diastolic_mmHg_today\": 76}'},\n",
              " {'question_number': 2,\n",
              "  'audio_file_in': 'q2_es.wav',\n",
              "  'spanish_question': '¿Cuáles fueron mis valores de presión arterial durante la última semana?',\n",
              "  'english_question': 'What were my blood pressure readings over the last week?',\n",
              "  'english_answer': 'Over the last week, your blood pressure readings were as follows: On October 10, your systolic was 160 mm Hg and diastolic was 101 mm Hg. On October 11, your systolic was 152 mm Hg and diastolic was 94 mm Hg. On October 12, your systolic was 157 mm Hg and diastolic was 98 mm Hg. On October 13, your systolic was 144 mm Hg and diastolic was 100 mm Hg. On October 14, your systolic was 145 mm Hg and diastolic was 91 mm Hg. On October 15, your systolic was 124 mm Hg and diastolic was 81 mm Hg. On October 16, your systolic was 110 mm Hg and diastolic was 76 mm Hg.',\n",
              "  'spanish_answer': 'En la última semana, sus lecturas de presión arterial fueron las siguientes: El 10 de octubre, su presión sistólica fue de 160 mm Hg y la diastólica de 101 mm Hg. El 11 de octubre, su presión sistólica fue de 152 mm Hg y la diastólica de 94 mm Hg. El 12 de octubre, su presión sistólica fue de 157 mm Hg y la diastólica de 98 mm Hg. El 13 de octubre, su presión sistólica fue de 144 mm Hg y la diastólica de 100 mm Hg. El 14 de octubre, su presión sistólica fue de 145 mm Hg y la diastólica de 91 mm Hg. El 15 de octubre, su presión sistólica fue de 124 mm Hg y la diastólica de 81 mm Hg. El 16 de octubre, su presión sistólica fue de 110 mm Hg y la diastólica de 76 mm Hg.',\n",
              "  'audio_answer_file': '/content/drive/MyDrive/HealthTequity-LLM/results/tts_audio/answer_2_es.wav',\n",
              "  'computed_fields': '{\"October 10 systolic\": 160, \"October 10 diastolic\": 101, \"October 11 systolic\": 152, \"October 11 diastolic\": 94, \"October 12 systolic\": 157, \"October 12 diastolic\": 98, \"October 13 systolic\": 144, \"October 13 diastolic\": 100, \"October 14 systolic\": 145, \"October 14 diastolic\": 91, \"October 15 systolic\": 124, \"October 15 diastolic\": 81, \"October 16 systolic\": 110, \"October 16 diastolic\": 76}'},\n",
              " {'question_number': 3,\n",
              "  'audio_file_in': 'q3_es.wav',\n",
              "  'spanish_question': '¿Cuál es la tendencia de mis valores de presión arterial?',\n",
              "  'english_question': 'What is the trend of my blood pressure values?',\n",
              "  'english_answer': 'Over the last 30 days, your blood pressure has shown some fluctuations. Initially, your systolic and diastolic pressures were mostly within normal or slightly elevated ranges. However, starting from late September, there was a noticeable increase in both systolic and diastolic values, reaching hypertensive levels. This trend continued into early October, with several days of high readings. Towards mid-October, your blood pressure began to decrease, returning to normal or elevated levels by October 16.',\n",
              "  'spanish_answer': 'En los últimos 30 días, su presión arterial ha mostrado algunas fluctuaciones. Inicialmente, sus presiones sistólica y diastólica estaban mayormente dentro de rangos normales o ligeramente elevados. Sin embargo, a partir de finales de septiembre, hubo un aumento notable en ambos valores, alcanzando niveles hipertensivos. Esta tendencia continuó a principios de octubre, con varios días de lecturas altas. Hacia mediados de octubre, su presión arterial comenzó a disminuir, volviendo a niveles normales o elevados para el 16 de octubre.',\n",
              "  'audio_answer_file': '/content/drive/MyDrive/HealthTequity-LLM/results/tts_audio/answer_3_es.wav',\n",
              "  'computed_fields': '{\"systolic_trend\": \"increase from normal to hypertensive, then decrease\", \"diastolic_trend\": \"increase from normal to hypertensive, then decrease\"}'},\n",
              " {'question_number': 4,\n",
              "  'audio_file_in': 'q4_es.wav',\n",
              "  'spanish_question': '¿Cuáles son los rango normales para una persona como yo?',\n",
              "  'english_question': 'What are the normal ranges for a person like me?',\n",
              "  'english_answer': 'Based on your age (68 years) and sex (Female), typical blood pressure values are approximately less than 120/80 mm Hg for normal blood pressure, according to the American Heart Association. Elevated blood pressure is considered to be systolic between 120-129 mm Hg and diastolic less than 80 mm Hg. Hypertension Stage 1 is systolic between 130-139 mm Hg or diastolic between 80-89 mm Hg.',\n",
              "  'spanish_answer': 'Según su edad (68 años) y sexo (femenino), los valores típicos de presión arterial son aproximadamente menos de 120/80 mm Hg para una presión arterial normal, de acuerdo con la Asociación Americana del Corazón. La presión arterial elevada se considera cuando la sistólica está entre 120-129 mm Hg y la diastólica es menor de 80 mm Hg. La hipertensión en etapa 1 se define como sistólica entre 130-139 mm Hg o diastólica entre 80-89 mm Hg.',\n",
              "  'audio_answer_file': '/content/drive/MyDrive/HealthTequity-LLM/results/tts_audio/answer_4_es.wav',\n",
              "  'computed_fields': '{\"age\": 68, \"sex\": \"Female\", \"normal_range\": \"<120/80 mm Hg\"}'},\n",
              " {'question_number': 5,\n",
              "  'audio_file_in': 'q5_es.wav',\n",
              "  'spanish_question': '¿Cuál era mi presión arterial el 10 de octubre?',\n",
              "  'english_question': 'What was my blood pressure on October 10th?',\n",
              "  'english_answer': 'On October 10th, your systolic blood pressure was 160 mm Hg and your diastolic pressure was 101 mm Hg.',\n",
              "  'spanish_answer': 'El 10 de octubre, su presión arterial sistólica fue de 160 mm Hg y su presión diastólica fue de 101 mm Hg.',\n",
              "  'audio_answer_file': '/content/drive/MyDrive/HealthTequity-LLM/results/tts_audio/answer_5_es.wav',\n",
              "  'computed_fields': '{\"systolic_mmHg\": 160, \"diastolic_mmHg\": 101}'},\n",
              " {'question_number': 6,\n",
              "  'audio_file_in': 'q6_es.wav',\n",
              "  'spanish_question': '¿En qué día mi presión arterial excedió los niveles normales? Compare mi presión arterial promedio en la primera semana y la última semana de este mes. ¿Cuál fue mi presión arterial diastólica más baja este mes?',\n",
              "  'english_question': 'On which day did my blood pressure exceed normal levels? Compare my average blood pressure in the first week and the last week of this month. What was my lowest diastolic blood pressure this month?',\n",
              "  'english_answer': 'Your blood pressure exceeded normal levels on several days. Specifically, it was elevated or hypertensive on September 18, 19, 24, 25, 26, 27, 28, 29, 30, and October 1, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, and 15. In the first week of this month (September 17 to 23), your average systolic pressure was approximately 117.86 mm Hg and your diastolic pressure was approximately 75.00 mm Hg. In the last week (October 10 to 16), your average systolic pressure was approximately 141.14 mm Hg and your diastolic pressure was approximately 91.57 mm Hg. The lowest diastolic blood pressure this month was 68 mm Hg on October 4.',\n",
              "  'spanish_answer': 'Su presión arterial superó los niveles normales en varios días. Específicamente, estuvo elevada o hipertensiva el 18, 19, 24, 25, 26, 27, 28, 29, 30 de septiembre, y el 1, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14 y 15 de octubre. En la primera semana de este mes (del 17 al 23 de septiembre), su presión sistólica promedio fue de aproximadamente 117.86 mm Hg y su presión diastólica fue de aproximadamente 75.00 mm Hg. En la última semana (del 10 al 16 de octubre), su presión sistólica promedio fue de aproximadamente 141.14 mm Hg y su presión diastólica fue de aproximadamente 91.57 mm Hg. La presión diastólica más baja de este mes fue de 68 mm Hg el 4 de octubre.',\n",
              "  'audio_answer_file': '/content/drive/MyDrive/HealthTequity-LLM/results/tts_audio/answer_6_es.wav',\n",
              "  'computed_fields': '{\"days_exceeded_normal\": [\"September 18\", \"September 19\", \"September 24\", \"September 25\", \"September 26\", \"September 27\", \"September 28\", \"September 29\", \"September 30\", \"October 1\", \"October 3\", \"October 4\", \"October 7\", \"October 8\", \"October 9\", \"October 10\", \"October 11\", \"October 12\", \"October 13\", \"October 14\", \"October 15\"], \"first_week_average_systolic\": 117.86, \"first_week_average_diastolic\": 75.0, \"last_week_average_systolic\": 141.14, \"last_week_average_diastolic\": 91.57, \"lowest_diastolic\": 68}'}]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# THis is the end of what I did"
      ],
      "metadata": {
        "id": "-m8DH9fbZR79"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}